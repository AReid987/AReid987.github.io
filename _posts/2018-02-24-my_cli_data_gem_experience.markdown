---
layout: post
title:      "My CLI Data Gem Experience "
date:       2018-02-24 22:10:35 +0000
permalink:  my_cli_data_gem_experience
---

 
     This was a fun and highly educational project, that left me feeling pretty accomplished. In working through this one, a few things started to 'click'. In essence, this project is effectively doing just two things : scraping a public site and creating objects. The object's attributes are assigned using the data being scraped and a CLI gives access to a user. While working with these objects and iterating through the Nokogiri XML collection, it dawned on me that these things, which seemed so foreign to me only just recently, now made (mostly) complete sense. 
		 
		 I think I may have gotten a bit of extra learning from this project as well, due to the fact that my first program did not work and I was forced to start over. Unbeknownst to me, you absolutely CANNOT scrape yelp.com. In my first attempt at this project, my goal was to create a CLI Gem that would allow a user to enter a zipcode and return a list of music venues nearby, through the process of scraping yelp. I was actually able to complete the entire program and it even worked a few times. However, I then started receiving the dreaded 503 error on subsequent attempts to run my program. After some digging around and learning a few new things, i.e. that some sites have a robot.txt page indicating their sraping policies, I found in the yelp support pages explicitly : "In short: please donâ€™t scrape our site!". With no other option, I regrouped and decided to make a Gem that would print songs from the billboard top 100, with the number of songs returned to be chosen by the user. 
		 
		 I found the resources provided on the learn.co project page incredibly useful. In the walkthrough video made by Avi, he talks about how to begin a project such as this one. I hadn't previously considered the idea of beginning at the point where the user interacts with the program. It really allowed for a more organized approach, in that it gave the program a sort of dimensionality - at least from my perspective. It kind of made it possible to view the program as a place, maybe something like a road network. The user is interacting at intersection A, the scraping of a site happens over here at intersection C, and in between at intersection B new objects are created, assigned properties to be finally delivered to the user back at A. 
		 
		 After planning the interface I wanted the user to experience on paper, I followed the process of stubbing out the CLI using hard coded data. I adhered to the advice of keeping only the next couple of steps in mind and just working to make progress, since you can only discover which code won't work by making the program more 'real'.  Once I had an interface working with hard coded data, I then began to create objects and assign them attributes using the hard data. Finally, I was able to scrape from the billboard.com site and create objects that were not hard coded! I did run into an issue while attempting to assign song objects the attribute of artist. Some of the artists listed on the website were inside of <a> tags, meanwhile others were in <span> tags. I tried an unneccesarily complicted approach of using conditional logic to determine which tag was present based on the current array index being iterated on. Then, it occured to me that although the tags were different, both cases used the same class. I simply removed the tag from the #css method call and it worked! Solving an issue in a program is always such a great feeling. 
		 
		 To allow access to a deeper level for each song object, the method #print_song was added. A programatic maze is traversed to return a song based on the user's input. First, the Song class stores all newly created song objects into a class variable @@all_songs. Then, this class variable is stored into an instance variable @songs in the CLI class. After the songs are listed by #list_songs, each with a sequential number before the title, the user is prompted to enter a number for the song they'd like to see. That number is captured by #gets, converted to an integer and then used as an array index for the @songs instance variable, which as previously mentioned, stores the @@all_songs array. The chosen index is puts'ed using string interpolation to gather all of that object's attributes.
		 
		 With a working interface, that was properly scraping and creating objects, it was time to refactor. Since I had so many responsibilities assigned to just one method in my Song class, I decided to add some new methods. The class responsible for Song objects was scraping, creating objects and assiging attributes all inside of just one method. To remedy this, I added another class just for scraping. One method, #open_page would return the Nokogiri XML collection, another method, #scrape_songs to select the nested node containing all of the soon to be song objects, and finally a method #make_songs was added to iterate over that nested node and call #create_songs on each element returned by #scrape_songs. With this new program structure, I could keep each method to more or less one responsibility as well as improve the readability. 
		 
		 With everything functioning properly, the next step was to add the flexibility of allowing the user to choose how many songs they wanted to see. To accomplish this I added a class variable @@song_number to the CLI class. When the user is prompted by the CLI to enter the number of songs they'd like to see, that number is stored in the class variable @@song_number. Then, over in the SongScraper class, at the point at which the Nokogiri XML elements are passed to the Song class to be born as objects, I added a bit of conditional logic. When the SongScraper #make_songs method iterates over the collection returned by #scrape_songs, the Song class' #create_songs is called on each element. With the new condition, #create_songs is only called if the length of the Song class variable @@all_songs (an array of all songs created) is less than or equal to the CLI class variable @@song_number, which stores the number entered by the user. This was a better implementation than my first which was to use a counter variable. Since @@all_songs grows in length with every song created, it was easy enough to use it's length against the user input for the condition deciding how many songs to be created. 
		 
		 The last step was to add the option for the user to run the program again before exiting. This required only a couple of simple steps. The first being to add an if/elsif statement in the #goodbye method in the CLI class. The user is prompted to answer whether or not they want to try a different number of songs. If the input is 'y' or 'yes' the #call method is invoked. The second step was to invoke #clear on the @@all_songs array at the beginning of the #call method. Otherwise, the previously created song objects would still be in the @@all_song array.
		 
		 After finishing the project, I published my first Gem to rubygems.com! This took a few attempts and a few google searches. I learn that removing the if/else statement from the gemspec file was necessary. I also needed to run a gem build as well as download the rubygems api. When that was completed, running the gem push command published my gem to rubygems. 
		 
		 Ultimately, my experience with this project was great. It was challenging and rewarding. I am extremely happy to have completed it and look forward to learning more. 
